{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4be6cf",
   "metadata": {},
   "source": [
    "### 1) Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9304590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHeader Tags in Wikipidea\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Header\n",
       "0  From today's featured article\n",
       "1               Did you know ...\n",
       "2                    In the news\n",
       "3                    On this day\n",
       "4       Today's featured picture\n",
       "5       Other areas of Wikipedia\n",
       "6    Wikipedia's sister projects\n",
       "7            Wikipedia languages"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get ('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup1=BeautifulSoup(page.text)\n",
    "\n",
    "Headline=[] # empty list for store the\n",
    "for i in soup1.find_all('h2',class_=\"mp-h2\"):\n",
    "    Headline.append(i.text)\n",
    "\n",
    "# making dataframes\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Header':Headline})\n",
    "print('\\033[1m'+'Header Tags in Wikipidea'+'\\033[0m')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a8f9ac",
   "metadata": {},
   "source": [
    "### 2) Write a python program to display IMDB’s Top rated 50 movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4f94e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of movie</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.The Godfather(1972)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.Schindler's List(1993)</td>\n",
       "      <td>9</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.12 Angry Men(1957)</td>\n",
       "      <td>9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.La vita è bella(1997)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.Il buono, il brutto, il cattivo(1966)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.The Shawshank Redemption(1994)</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.The Pursuit of Happyness(2006)</td>\n",
       "      <td>8</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.Shichinin no samurai(1954)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.The Intouchables(2011)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.Central do Brasil(1998)</td>\n",
       "      <td>8</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.Requiem for a Dream(2000)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.A Beautiful Mind(2001)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.Hachi: A Dog's Tale(2009)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.Taken(I) (2008)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(I) (2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.Yeopgijeogin geunyeo(2001)</td>\n",
       "      <td>8</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.Amores perros(2000)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.The Shining(1980)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.Apocalypto(2006)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.Gladiator(2000)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.Cast Away(2000)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.The Dark Knight(2008)</td>\n",
       "      <td>9</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.The Pianist(2002)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.Titanic(1997)</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.Bin-jip(2004)</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.Braveheart(1995)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.It's a Wonderful Life(1946)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.Bom yeoreum gaeul gyeoul geurigo bom(2003)</td>\n",
       "      <td>8</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.Alien(1979)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.Salinui chueok(2003)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.Vozvrashchenie(2003)</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.Ang-ma-reul bo-at-da(2010)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.Bacheha-Ye aseman(1997)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.Jodaeiye Nader az Simin(2011)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.The Sixth Sense(1999)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.Nae meorisokui jiwoogae(2004)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.Okuribito(2008)</td>\n",
       "      <td>8</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.Wo de fu qin mu qin(1999)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.Saving Private Ryan(1998)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.The Bridge on the River Kwai(1957)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.Ben-Hur(1959)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.The Exorcist(1973)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1973)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.El secreto de sus ojos(2009)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.Léon(1994)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.The Green Mile(1999)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.Gran Torino(2008)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.Kill Bill: Vol. 1(2003)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.Jurassic Park(1993)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.Terminator 2: Judgment Day(1991)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.Back to the Future(1985)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.Finding Nemo(2003)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name of movie Rating Year of release\n",
       "0                           1.The Godfather(1972)    9.2          (1972)\n",
       "1                        2.Schindler's List(1993)      9          (1993)\n",
       "2                            3.12 Angry Men(1957)      9          (1957)\n",
       "3                         4.La vita è bella(1997)    8.6          (1997)\n",
       "4         5.Il buono, il brutto, il cattivo(1966)    8.8          (1966)\n",
       "5                6.The Shawshank Redemption(1994)    9.3          (1994)\n",
       "6                7.The Pursuit of Happyness(2006)      8          (2006)\n",
       "7                    8.Shichinin no samurai(1954)    8.6          (1954)\n",
       "8                        9.The Intouchables(2011)    8.5          (2011)\n",
       "9                      10.Central do Brasil(1998)      8          (1998)\n",
       "10                   11.Requiem for a Dream(2000)    8.3          (2000)\n",
       "11                      12.A Beautiful Mind(2001)    8.2          (2001)\n",
       "12                   13.Hachi: A Dog's Tale(2009)    8.1          (2009)\n",
       "13                             14.Taken(I) (2008)    7.8      (I) (2008)\n",
       "14                  15.Yeopgijeogin geunyeo(2001)      8          (2001)\n",
       "15                         16.Amores perros(2000)    8.1          (2000)\n",
       "16                           17.The Shining(1980)    8.4          (1980)\n",
       "17                            18.Apocalypto(2006)    7.8          (2006)\n",
       "18                             19.Gladiator(2000)    8.5          (2000)\n",
       "19                             20.Cast Away(2000)    7.8          (2000)\n",
       "20                       21.The Dark Knight(2008)      9          (2008)\n",
       "21                           22.The Pianist(2002)    8.5          (2002)\n",
       "22                               23.Titanic(1997)    7.9          (1997)\n",
       "23                               24.Bin-jip(2004)    7.9          (2004)\n",
       "24                            25.Braveheart(1995)    8.4          (1995)\n",
       "25                 26.It's a Wonderful Life(1946)    8.6          (1946)\n",
       "26  27.Bom yeoreum gaeul gyeoul geurigo bom(2003)      8          (2003)\n",
       "27                                 28.Alien(1979)    8.5          (1979)\n",
       "28                        29.Salinui chueok(2003)    8.1          (2003)\n",
       "29                        30.Vozvrashchenie(2003)    7.9          (2003)\n",
       "30                  31.Ang-ma-reul bo-at-da(2010)    7.8          (2010)\n",
       "31                     32.Bacheha-Ye aseman(1997)    8.2          (1997)\n",
       "32               33.Jodaeiye Nader az Simin(2011)    8.3          (2011)\n",
       "33                       34.The Sixth Sense(1999)    8.2          (1999)\n",
       "34               35.Nae meorisokui jiwoogae(2004)    8.1          (2004)\n",
       "35                             36.Okuribito(2008)      8          (2008)\n",
       "36                   37.Wo de fu qin mu qin(1999)    7.8          (1999)\n",
       "37                   38.Saving Private Ryan(1998)    8.6          (1998)\n",
       "38          39.The Bridge on the River Kwai(1957)    8.2          (1957)\n",
       "39                               40.Ben-Hur(1959)    8.1          (1959)\n",
       "40                          41.The Exorcist(1973)    8.1          (1973)\n",
       "41                42.El secreto de sus ojos(2009)    8.2          (2009)\n",
       "42                                  43.Léon(1994)    8.5          (1994)\n",
       "43                        44.The Green Mile(1999)    8.6          (1999)\n",
       "44                           45.Gran Torino(2008)    8.1          (2008)\n",
       "45                     46.Kill Bill: Vol. 1(2003)    8.2          (2003)\n",
       "46                         47.Jurassic Park(1993)    8.2          (1993)\n",
       "47            48.Terminator 2: Judgment Day(1991)    8.6          (1991)\n",
       "48                    49.Back to the Future(1985)    8.5          (1985)\n",
       "49                          50.Finding Nemo(2003)    8.2          (2003)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get ('https://www.imdb.com/list/ls055386972/')\n",
    "soup2=BeautifulSoup(page.content)\n",
    "\n",
    "#Name of Movie\n",
    "Name=[] # empty list for store the\n",
    "for i in soup2.find_all('h3',class_=\"lister-item-header\"):\n",
    "    Name.append(i.get_text().split('|')[0].replace(\"\\n\",\"\"))\n",
    "    \n",
    "# Year of Release\n",
    "year_of_release=[]\n",
    "for i in soup2.find_all('span',class_=\"lister-item-year text-muted unbold\"):\n",
    "    year_of_release.append(i.text)\n",
    "    \n",
    "# Rating\n",
    "Rating=[]\n",
    "for i in soup2.find_all('div',class_=\"ipl-rating-star small\"):\n",
    "    Rating.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "    \n",
    "# making dataframes\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name of movie':Name,'Rating':Rating,'Year of release':year_of_release})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b9596",
   "metadata": {},
   "source": [
    "### 3) Write a python program to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e08ba77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mIMDB’s Top rated 50 Indian movies\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of movie</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      Ramayana: The Legend of Prince R...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      Rocketry: The Nambi Effect(2022)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      Nayakan(1987)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      Gol Maal(1979)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      777 Charlie(2022)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.      Anbe Sivam(2003)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.      Pariyerum Perumal(2018)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.      Apur Sansar(1959)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.      3 Idiots(2009)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.      Jai Bhim(2021)</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.      Manichitrathazhu(1993)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.      #Home(2021)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.      Soorarai Pottru(2020)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.      Black Friday(2004)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.      Kumbalangi Nights(2019)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.      C/o Kancharapalem(2018)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.      Taare Zameen Par(2007)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.      Kireedam(1989)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.      Dangal(2016)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.      Kaithi(2019)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.      Jersey(2019)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.      96(2018)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.      Maya Bazaar(1957)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.      Natsamrat(2016)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.      Asuran(2019)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.      Drishyam 2(2021)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.      Sita Ramam(2022)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.      Thevar Magan(1992)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.      Visaaranai(2015)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.      Sarpatta Parambarai(2021)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.      Thalapathi(1991)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.      Nadodikkattu(1987)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.      Pather Panchali(1955)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34.      Drishyam(2013)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.      Thani Oruvan(2015)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36.      Jaane Bhi Do Yaaro(1983)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37.      Vada Chennai(2018)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.      Aparajito(1956)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39.      Khosla Ka Ghosla!(2006)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.      Sardar Udham(2021)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41.      Anniyan(2005)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42.      Ratsasan(2018)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43.      Chupke Chupke(1975)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44.      Gangs of Wasseypur(2012)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45.      Drishyam(2015)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46.      Peranbu(2018)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47.      Bangalore Days(2014)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48.      Mahanati(2018)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49.      Satya(1998)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50.      Premam(2015)</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name of movie Rating Year of release\n",
       "0         1.      Ramayana: The Legend of Prince R...    8.6          (1993)\n",
       "1            2.      Rocketry: The Nambi Effect(2022)    8.4          (2022)\n",
       "2                               3.      Nayakan(1987)    8.4          (1987)\n",
       "3                              4.      Gol Maal(1979)    8.4          (1979)\n",
       "4                           5.      777 Charlie(2022)    8.4          (2022)\n",
       "5                            6.      Anbe Sivam(2003)    8.4          (2003)\n",
       "6                     7.      Pariyerum Perumal(2018)    8.4          (2018)\n",
       "7                           8.      Apur Sansar(1959)    8.4          (1959)\n",
       "8                              9.      3 Idiots(2009)    8.4          (2009)\n",
       "9                             10.      Jai Bhim(2021)    8.4          (2021)\n",
       "10                    11.      Manichitrathazhu(1993)    8.3          (1993)\n",
       "11                               12.      #Home(2021)    8.3          (2021)\n",
       "12                     13.      Soorarai Pottru(2020)    8.3          (2020)\n",
       "13                        14.      Black Friday(2004)    8.3          (2004)\n",
       "14                   15.      Kumbalangi Nights(2019)    8.3          (2019)\n",
       "15                   16.      C/o Kancharapalem(2018)    8.3          (2018)\n",
       "16                    17.      Taare Zameen Par(2007)    8.3          (2007)\n",
       "17                            18.      Kireedam(1989)    8.3          (1989)\n",
       "18                              19.      Dangal(2016)    8.3          (2016)\n",
       "19                              20.      Kaithi(2019)    8.3          (2019)\n",
       "20                              21.      Jersey(2019)    8.3          (2019)\n",
       "21                                  22.      96(2018)    8.3          (2018)\n",
       "22                         23.      Maya Bazaar(1957)    8.2          (1957)\n",
       "23                           24.      Natsamrat(2016)    8.2          (2016)\n",
       "24                              25.      Asuran(2019)    8.2          (2019)\n",
       "25                          26.      Drishyam 2(2021)    8.2          (2021)\n",
       "26                          27.      Sita Ramam(2022)    8.2          (2022)\n",
       "27                        28.      Thevar Magan(1992)    8.2          (1992)\n",
       "28                          29.      Visaaranai(2015)    8.2          (2015)\n",
       "29                 30.      Sarpatta Parambarai(2021)    8.2          (2021)\n",
       "30                          31.      Thalapathi(1991)    8.2          (1991)\n",
       "31                        32.      Nadodikkattu(1987)    8.2          (1987)\n",
       "32                     33.      Pather Panchali(1955)    8.2          (1955)\n",
       "33                            34.      Drishyam(2013)    8.2          (2013)\n",
       "34                        35.      Thani Oruvan(2015)    8.2          (2015)\n",
       "35                  36.      Jaane Bhi Do Yaaro(1983)    8.2          (1983)\n",
       "36                        37.      Vada Chennai(2018)    8.2          (2018)\n",
       "37                           38.      Aparajito(1956)    8.2          (1956)\n",
       "38                   39.      Khosla Ka Ghosla!(2006)    8.2          (2006)\n",
       "39                        40.      Sardar Udham(2021)    8.2          (2021)\n",
       "40                             41.      Anniyan(2005)    8.2          (2005)\n",
       "41                            42.      Ratsasan(2018)    8.1          (2018)\n",
       "42                       43.      Chupke Chupke(1975)    8.1          (1975)\n",
       "43                  44.      Gangs of Wasseypur(2012)    8.1          (2012)\n",
       "44                            45.      Drishyam(2015)    8.1          (2015)\n",
       "45                             46.      Peranbu(2018)    8.1          (2018)\n",
       "46                      47.      Bangalore Days(2014)    8.1          (2014)\n",
       "47                            48.      Mahanati(2018)    8.1          (2018)\n",
       "48                               49.      Satya(1998)    8.1          (1998)\n",
       "49                              50.      Premam(2015)    8.1          (2015)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# Send get request to the webpage server to get the source code of the page\n",
    "page = requests.get ('https://www.imdb.com/india/top-rated-indian-movies')\n",
    "soup3=BeautifulSoup(page.content)\n",
    "\n",
    "# Name of Movie\n",
    "movie_string=[] # empty list \n",
    "for i in soup3.find_all('td',class_=\"titleColumn\"):\n",
    "    movie_string.append(i.get_text().split(\"|\")[0].replace(\"\\n\",\"\"))\n",
    "    \n",
    "Name = movie_string[0:50]  \n",
    "\n",
    "# scrapping rating\n",
    "rating=[]\n",
    "for i in soup3.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    rating.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "Rating=rating[0:50] \n",
    "\n",
    "# scrapping year of release\n",
    "year_of_release=[]\n",
    "for i in soup3.find_all('span',class_=\"secondaryInfo\"):\n",
    "    year_of_release.append(i.text)\n",
    "    \n",
    "year=year_of_release[0:50]\n",
    "\n",
    "# making dataframes\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name of movie':Name,'Rating':Rating,'Year of release':year})\n",
    "print('\\033[1m'+'IMDB’s Top rated 50 Indian movies'+'\\033[0m')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95ca70",
   "metadata": {},
   "source": [
    "### 4) Write python program to display list of respected former presidents of India(i.e. Name , Term ofoffice) from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b800acdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFormer presidents of India\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of President</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name of President  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                       Term of Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get ('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "\n",
    "# page content\n",
    "soup4=BeautifulSoup(page.content)\n",
    "\n",
    "# Name of President\n",
    "first_title2=[]\n",
    "for i in soup4.find_all('h3'):\n",
    "    first_title2.append(i.text)\n",
    "    \n",
    "#Term of Office\n",
    "office = [] # creating the empty list\n",
    "for i in soup4.find_all(\"div\",class_=\"presidentListing\"):\n",
    "     office.append(i.find_all(\"p\")[0].text.split(\":\")[1])\n",
    "        \n",
    "        \n",
    "# making dataframes\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name of President':first_title2,'Term of Office':office})\n",
    "print('\\033[1m'+'Former presidents of India'+'\\033[0m')\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56ceba",
   "metadata": {},
   "source": [
    "### 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "    a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "    b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "    c) Top 10 ODI bowlers along with the records of their team andrating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69435d",
   "metadata": {},
   "source": [
    "##### a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db7472d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mICC MENS ODI RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>35</td>\n",
       "      <td>3,965</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>3,504</td>\n",
       "      <td>3,504</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>5,294</td>\n",
       "      <td>5,294</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>3,988</td>\n",
       "      <td>3,988</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>2,649</td>\n",
       "      <td>2,649</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches Points Rating\n",
       "0     Australia      35  3,965    113\n",
       "1   New Zealand      31     31    113\n",
       "2         India   3,504  3,504    111\n",
       "3       England      47     47    106\n",
       "4      Pakistan   5,294  5,294    101\n",
       "5  South Africa      36     36     95\n",
       "6    Bangladesh   3,988  3,988     86\n",
       "7     Sri Lanka      25     25     72\n",
       "8   West Indies   2,649  2,649     71\n",
       "9   Afghanistan      31     31     51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "page = requests.get ('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup5=BeautifulSoup(page.content)\n",
    "\n",
    "# Top 10 ODI teams\n",
    "team=[]\n",
    "\n",
    "\n",
    "for i in soup5.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "team=team[0:10]\n",
    "\n",
    "Matches=[]\n",
    "match=soup5.find_all('td',class_='rankings-block__banner--matches')\n",
    "matchs=soup5.find_all('td',class_='table-body__cell u-center-text')\n",
    "mtc = match + matchs\n",
    "\n",
    "# Record of matches\n",
    "for i in mtc:\n",
    "    Matches.append(i.text)\n",
    "    Matches=Matches[0:10]\n",
    "    \n",
    "# Points\n",
    "Points=[]\n",
    "\n",
    "pt=soup5.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "pts= soup5.find_all('td',class_ =\"table-body__cell u-center-text\")\n",
    "Point= pt + pts\n",
    "for i in Point:\n",
    "    Points.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Points=Points[0:10]\n",
    "\n",
    "# Ratings   \n",
    "Rating=[]\n",
    "rating = soup5.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "for i in rating:\n",
    "    Rating.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Rating=Rating[0:10]\n",
    "    \n",
    "# making dataframes\n",
    "\n",
    "df=pd.DataFrame({'Country':team,'Matches':Matches,'Points':Points,'Rating':Rating})\n",
    "print('\\033[1m'+'ICC MENS ODI RANKING'+'\\033[0m') # Print Title in bold case\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ad522",
   "metadata": {},
   "source": [
    "#### b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5775d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI MENS BATTING RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td></td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6         ...</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9         ...</td>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11        ...</td>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Ranking            Player_Name  \\\n",
       "0   \\n\\n\\n                            1\\n         ...             Babar Azam   \n",
       "1                                       2         ...  Rassie van der Dussen   \n",
       "2                                       3         ...            Imam-ul-Haq   \n",
       "3                                       4         ...           Shubman Gill   \n",
       "4                                       5         ...           David Warner   \n",
       "5                                       6         ...            Virat Kohli   \n",
       "6                                       7         ...        Quinton de Kock   \n",
       "7                                       8         ...           Rohit Sharma   \n",
       "8                                       9         ...            Steve Smith   \n",
       "9                                       10        ...           Fakhar Zaman   \n",
       "10                                      11        ...              Shai Hope   \n",
       "\n",
       "   Team Rating  \n",
       "0          887  \n",
       "1    SA    777  \n",
       "2   PAK    740  \n",
       "3   IND    738  \n",
       "4   AUS    726  \n",
       "5   IND    719  \n",
       "6    SA    718  \n",
       "7   IND    707  \n",
       "8   AUS    702  \n",
       "9   PAK    699  \n",
       "10   WI    698  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ICC Bating Ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup5b= BeautifulSoup(response.content, 'lxml')\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup5b.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup5b.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Storing data in Dataframe\n",
    "ODI_Batmans=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "print('\\033[1m'+'ICC ODI MENS BATTING RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI_Batmans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7be24f2",
   "metadata": {},
   "source": [
    "##### c) Top 10 ODI bowlers along with the records of their team andrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960bdd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI MENS BOWLING RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td></td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6         ...</td>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9         ...</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11        ...</td>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Ranking       Player_Name Team  \\\n",
       "0   \\n\\n\\n                            1\\n         ...    Josh Hazlewood        \n",
       "1                                       2         ...       Trent Boult   NZ   \n",
       "2                                       3         ...    Mohammed Siraj  IND   \n",
       "3                                       4         ...    Mitchell Starc  AUS   \n",
       "4                                       5         ...        Matt Henry   NZ   \n",
       "5                                       6         ...       Rashid Khan  AFG   \n",
       "6                                       7         ...        Adam Zampa  AUS   \n",
       "7                                       8         ...    Shaheen Afridi  PAK   \n",
       "8                                       9         ...  Mujeeb Ur Rahman  AFG   \n",
       "9                                       10        ...   Shakib Al Hasan  BAN   \n",
       "10                                      11        ...     Mohammad Nabi  AFG   \n",
       "\n",
       "   Rating  \n",
       "0     705  \n",
       "1     694  \n",
       "2     691  \n",
       "3     686  \n",
       "4     676  \n",
       "5     659  \n",
       "6     652  \n",
       "7     641  \n",
       "8     637  \n",
       "9     636  \n",
       "10    631  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ICC ODI Mens Bowling Ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup5c= BeautifulSoup(response.content, 'lxml')\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup5c.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup5c.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Storing data in Dataframe\n",
    "ODI_Bowling=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "print('\\033[1m'+'ICC ODI MENS BOWLING RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI_Bowling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c5198",
   "metadata": {},
   "source": [
    "### 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "    a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "    b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "    c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cba00c",
   "metadata": {},
   "source": [
    "##### a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ccecb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/womens/team-rankings/odi\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI WOMENS RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>172               ...</td>\n",
       "      <td>3,603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>119</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "      <td>3,342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>26</td>\n",
       "      <td>104</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>3,098</td>\n",
       "      <td>102</td>\n",
       "      <td>3,098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>94</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>2,820</td>\n",
       "      <td>76</td>\n",
       "      <td>2,820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2,553</td>\n",
       "      <td>62</td>\n",
       "      <td>2,553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>27</td>\n",
       "      <td>44</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches                                             Rating  \\\n",
       "0     Australia      21                              172               ...   \n",
       "1       England      28                                                119   \n",
       "2  South Africa   3,342                                                119   \n",
       "3         India      26                                                104   \n",
       "4   New Zealand   3,098                                                102   \n",
       "5   West Indies      27                                                 94   \n",
       "6    Bangladesh   2,820                                                 76   \n",
       "7      Thailand      25                                                 72   \n",
       "8      Pakistan   2,553                                                 62   \n",
       "9     Sri Lanka      27                                                 44   \n",
       "\n",
       "  Points  \n",
       "0  3,603  \n",
       "1     28  \n",
       "2  3,342  \n",
       "3     26  \n",
       "4  3,098  \n",
       "5     27  \n",
       "6  2,820  \n",
       "7     25  \n",
       "8  2,553  \n",
       "9     27  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n')\n",
    "SOUP6a= BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "# Creating empty list\n",
    "Team=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "\n",
    "# Extracting Team Name\n",
    "Country = SOUP6a.find_all('span',class_=\"u-hide-phablet\")\n",
    "for i in Country:\n",
    "    Team.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Team=Team[0:10]\n",
    "    \n",
    "# Extracting No of Matches    \n",
    "match=SOUP6a.find_all('td',class_='rankings-block__banner--matches')\n",
    "matchs=SOUP6a.find_all('td',class_='table-body__cell u-center-text')\n",
    "mtc = match + matchs\n",
    "for i in  mtc:\n",
    "    Matches.append(i.text)\n",
    "    Matches=Matches[0:10]\n",
    "    \n",
    "# Extracting Points gain    \n",
    "pt=SOUP6a.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "pts= SOUP6a.find_all('td',class_ =\"table-body__cell u-center-text\")\n",
    "Point= pt + pts\n",
    "for i in Point:\n",
    "    Points.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Points=Points[0:10]\n",
    "    \n",
    "# Extracting Rating\n",
    "rat=SOUP6a.find_all('td',class_=\"rankings-block__banner--rating\")\n",
    "\n",
    "rating = SOUP6a.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "RATING=rat + rating\n",
    "for i in RATING:\n",
    "    Rating.append(i.get_text().replace(\"\\n\",\"\"))\n",
    "    Rating=Rating[0:10]\n",
    "Rating\n",
    "\n",
    "# Creating dataframe to store data\n",
    "ODI=pd.DataFrame({})\n",
    "ODI['Country']=Team\n",
    "ODI['Matches']=Matches\n",
    "ODI['Rating']=Rating\n",
    "ODI['Points']=Points\n",
    "\n",
    "print('\\033[1m'+'ICC ODI WOMENS RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8bcfd7",
   "metadata": {},
   "source": [
    "#### b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38f47c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI WOMENS BATTING RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td></td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6         ...</td>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9         ...</td>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11        ...</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Ranking          Player_Name  \\\n",
       "0   \\n\\n\\n                            1\\n         ...         Alyssa Healy   \n",
       "1                                       2         ...          Beth Mooney   \n",
       "2                                       3         ...      Laura Wolvaardt   \n",
       "3                                       4         ...       Natalie Sciver   \n",
       "4                                       5         ...          Meg Lanning   \n",
       "5                                       6         ...     Harmanpreet Kaur   \n",
       "6                                       7         ...      Smriti Mandhana   \n",
       "7                                       8         ...       Rachael Haynes   \n",
       "8                                       9         ...  Chamari Athapaththu   \n",
       "9                                       10        ...    Amy Satterthwaite   \n",
       "10                                      11        ...         Ellyse Perry   \n",
       "\n",
       "   Team Rating  \n",
       "0          762  \n",
       "1   AUS    754  \n",
       "2    SA    732  \n",
       "3   ENG    731  \n",
       "4   AUS    717  \n",
       "5   IND    716  \n",
       "6   IND    714  \n",
       "7   AUS    680  \n",
       "8    SL    655  \n",
       "9    NZ    641  \n",
       "10  AUS    626  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ICC WOMENS Bating Ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup6b= BeautifulSoup(response.text, 'lxml')\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup6b.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup6b.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Storing data in Dataframe\n",
    "ODI_Batmans=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "print('\\033[1m'+'ICC ODI WOMENS BATTING RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI_Batmans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab6e5a",
   "metadata": {},
   "source": [
    "#### c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf81ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ---> https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mICC ODI WOMENS BOWLING RANKING\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n                            1\\n         ...</td>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td></td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2         ...</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3         ...</td>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4         ...</td>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5         ...</td>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6         ...</td>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7         ...</td>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8         ...</td>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9         ...</td>\n",
       "      <td>Rajeshwari Gayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10        ...</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11        ...</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Ranking          Player_Name  \\\n",
       "0   \\n\\n\\n                            1\\n         ...    Sophie Ecclestone   \n",
       "1                                       2         ...        Jess Jonassen   \n",
       "2                                       3         ...       Shabnim Ismail   \n",
       "3                                       4         ...         Megan Schutt   \n",
       "4                                       5         ...       Jhulan Goswami   \n",
       "5                                       6         ...      Hayley Matthews   \n",
       "6                                       7         ...           Kate Cross   \n",
       "7                                       8         ...       Ayabonga Khaka   \n",
       "8                                       9         ...  Rajeshwari Gayakwad   \n",
       "9                                       10        ...       Marizanne Kapp   \n",
       "10                                      11        ...        Deepti Sharma   \n",
       "\n",
       "   Team Rating  \n",
       "0          751  \n",
       "1   AUS    723  \n",
       "2    SA    722  \n",
       "3   AUS    704  \n",
       "4   IND    698  \n",
       "5    WI    660  \n",
       "6   ENG    655  \n",
       "7    SA    634  \n",
       "8   IND    617  \n",
       "9    SA    598  \n",
       "10  IND    589  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ICC ODI Womens Bowling Ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url)\n",
    "print(response.status_code, '--->',url)\n",
    "print('\\n\\n')\n",
    "soup6c= BeautifulSoup(response.text, 'html.parser')\n",
    "Position =[]\n",
    "Player =[]\n",
    "Country =[]\n",
    "Rating =[]\n",
    "\n",
    "# Extracting Data of Top Player from Banner\n",
    "block_1= soup6c.find('tr', attrs={'class':'rankings-block__banner'}) # contains Top Player ranking detail\n",
    "\n",
    "Position.append(block_1.find('td',class_='rankings-block__position').text)# Ranking Position\n",
    "Player.append(block_1.find('div', class_=\"rankings-block__banner--name-large\").text) # Extract Player Name\n",
    "Country.append(block_1.find('span', class_='rankings-block__banner--nation').text)# Extract Country Name\n",
    "Rating.append(block_1.find('div', class_=\"rankings-block__banner--rating\").text) # Extract Rating\n",
    "\n",
    "# Extracting other Player Ranking\n",
    "table_rows =soup6c.find_all('tr', attrs={'class':'table-body'})\n",
    "\n",
    "for row in table_rows[:10]:\n",
    "    Position.append(row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.replace('\\n',''))\n",
    "    Player.append(row.find('a').text)\n",
    "    Country.append(row.find('span', class_='table-body__logo-text').text)\n",
    "    Rating.append(row.find('td', class_='table-body__cell rating').text)\n",
    "    \n",
    "# Storing data in Dataframe\n",
    "ODI_Bowling=pd.DataFrame({'Ranking':Position,'Player_Name':Player, 'Team':Country, 'Rating':Rating})\n",
    "\n",
    "print('\\033[1m'+'ICC ODI WOMENS BOWLING RANKING'+'\\033[0m') # Print Title in bold case\n",
    "ODI_Bowling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bba6b7",
   "metadata": {},
   "source": [
    "#### 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame\n",
    "    i) Headline\n",
    "    ii) Time\n",
    "    iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f4c5ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLatest News Details from CNBC\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Head Line</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA reportedly planning to announce significan...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/epa-reportedly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How green mortgages can help finance an energy...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/green-mortgage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 reasons big bank earnings are super importan...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/3-reasons-big-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mixing these 2 parenting styles can help raise...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/parenting-styl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How ChatGPT is changing the job hiring process...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/chatgpt-is-bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This 51-year-old pays $725 a month to live in ...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/51-year-old-pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amateur golfer set to beat Tiger Woods' colleg...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/golfer-rose-zh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Microsoft's $13 billion bet on OpenAI carries ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/microsofts-com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Travel nursing can pay $187,000 for 9 months o...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/travel-nurse-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oracle and five consumer names are among Wall ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/software-giant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Analysts say these two streaming giants have m...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/analysts-are-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>As population shrinks, these companies will be...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/04/08/as-population-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Federal judge revokes FDA abortion pill approv...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/federal-judge-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lawmakers meet with Apple, Disney CEOs for tal...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/lawmakers-look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dollar General again found in violation of fed...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/dollar-general...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Commerce officials heading to China ahead of p...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/commerce-offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>McDonald's $200M burger and Colgate frozen las...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/mcdonalds-200m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1 in 3 people would quit for a 4-day workweek ...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/monstercom-1-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IRS may tax certain NFTs at a higher rate in t...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/irs-may-tax-ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Google VP says this is the best way to build a...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/google-vp-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DOE boosts program that help small manufacture...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/doe-invests-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S&amp;P 500 futures, Treasury yields gain as labor...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/sp-500-futures...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The 15 worst places to buy a home if you want ...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/worst-places-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Job growth totals 236,000 in March, near expec...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/jobs-report-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tim Cook shares one of his favorite tricks Ste...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/apple-ceo-tim-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Question: How are some bars boosting profits? ...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/trivia-night-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Uranium is having a 'renaissance.' What to kno...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/uranium-is-hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gold and mining ETFs are surging as the precio...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/gold-and-minin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gen Z cares about the environment. That's bad ...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/gen-z-expects-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Letting everyone who wants a job have one is n...</td>\n",
       "      <td>April 7, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/04/07/federal-reserv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Head Line           Time  \\\n",
       "0   EPA reportedly planning to announce significan...   14 Hours Ago   \n",
       "1   How green mortgages can help finance an energy...   16 Hours Ago   \n",
       "2   3 reasons big bank earnings are super importan...   16 Hours Ago   \n",
       "3   Mixing these 2 parenting styles can help raise...   17 Hours Ago   \n",
       "4   How ChatGPT is changing the job hiring process...   17 Hours Ago   \n",
       "5   This 51-year-old pays $725 a month to live in ...   17 Hours Ago   \n",
       "6   Amateur golfer set to beat Tiger Woods' colleg...   17 Hours Ago   \n",
       "7   Microsoft's $13 billion bet on OpenAI carries ...   18 Hours Ago   \n",
       "8   Travel nursing can pay $187,000 for 9 months o...   18 Hours Ago   \n",
       "9   Oracle and five consumer names are among Wall ...   18 Hours Ago   \n",
       "10  Analysts say these two streaming giants have m...   18 Hours Ago   \n",
       "11  As population shrinks, these companies will be...   18 Hours Ago   \n",
       "12  Federal judge revokes FDA abortion pill approv...  April 7, 2023   \n",
       "13  Lawmakers meet with Apple, Disney CEOs for tal...  April 7, 2023   \n",
       "14  Dollar General again found in violation of fed...  April 7, 2023   \n",
       "15  Commerce officials heading to China ahead of p...  April 7, 2023   \n",
       "16  McDonald's $200M burger and Colgate frozen las...  April 7, 2023   \n",
       "17  1 in 3 people would quit for a 4-day workweek ...  April 7, 2023   \n",
       "18  IRS may tax certain NFTs at a higher rate in t...  April 7, 2023   \n",
       "19  Google VP says this is the best way to build a...  April 7, 2023   \n",
       "20  DOE boosts program that help small manufacture...  April 7, 2023   \n",
       "21  S&P 500 futures, Treasury yields gain as labor...  April 7, 2023   \n",
       "22  The 15 worst places to buy a home if you want ...  April 7, 2023   \n",
       "23  Job growth totals 236,000 in March, near expec...  April 7, 2023   \n",
       "24  Tim Cook shares one of his favorite tricks Ste...  April 7, 2023   \n",
       "25  Question: How are some bars boosting profits? ...  April 7, 2023   \n",
       "26  Uranium is having a 'renaissance.' What to kno...  April 7, 2023   \n",
       "27  Gold and mining ETFs are surging as the precio...  April 7, 2023   \n",
       "28  Gen Z cares about the environment. That's bad ...  April 7, 2023   \n",
       "29  Letting everyone who wants a job have one is n...  April 7, 2023   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2023/04/08/epa-reportedly...  \n",
       "1   https://www.cnbc.com/2023/04/08/green-mortgage...  \n",
       "2   https://www.cnbc.com/2023/04/08/3-reasons-big-...  \n",
       "3   https://www.cnbc.com/2023/04/08/parenting-styl...  \n",
       "4   https://www.cnbc.com/2023/04/08/chatgpt-is-bei...  \n",
       "5   https://www.cnbc.com/2023/04/08/51-year-old-pa...  \n",
       "6   https://www.cnbc.com/2023/04/08/golfer-rose-zh...  \n",
       "7   https://www.cnbc.com/2023/04/08/microsofts-com...  \n",
       "8   https://www.cnbc.com/2023/04/08/travel-nurse-e...  \n",
       "9   https://www.cnbc.com/2023/04/08/software-giant...  \n",
       "10  https://www.cnbc.com/2023/04/08/analysts-are-b...  \n",
       "11  https://www.cnbc.com/2023/04/08/as-population-...  \n",
       "12  https://www.cnbc.com/2023/04/07/federal-judge-...  \n",
       "13  https://www.cnbc.com/2023/04/07/lawmakers-look...  \n",
       "14  https://www.cnbc.com/2023/04/07/dollar-general...  \n",
       "15  https://www.cnbc.com/2023/04/07/commerce-offic...  \n",
       "16  https://www.cnbc.com/2023/04/07/mcdonalds-200m...  \n",
       "17  https://www.cnbc.com/2023/04/07/monstercom-1-i...  \n",
       "18  https://www.cnbc.com/2023/04/07/irs-may-tax-ce...  \n",
       "19  https://www.cnbc.com/2023/04/07/google-vp-the-...  \n",
       "20  https://www.cnbc.com/2023/04/07/doe-invests-in...  \n",
       "21  https://www.cnbc.com/2023/04/07/sp-500-futures...  \n",
       "22  https://www.cnbc.com/2023/04/07/worst-places-t...  \n",
       "23  https://www.cnbc.com/2023/04/07/jobs-report-ma...  \n",
       "24  https://www.cnbc.com/2023/04/07/apple-ceo-tim-...  \n",
       "25  https://www.cnbc.com/2023/04/07/trivia-night-b...  \n",
       "26  https://www.cnbc.com/2023/04/07/uranium-is-hav...  \n",
       "27  https://www.cnbc.com/2023/04/07/gold-and-minin...  \n",
       "28  https://www.cnbc.com/2023/04/07/gen-z-expects-...  \n",
       "29  https://www.cnbc.com/2023/04/07/federal-reserv...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get ('https://www.cnbc.com/world/?region=world')\n",
    "soup7=BeautifulSoup(page.content)\n",
    "\n",
    "# Headline\n",
    "Headline=[]\n",
    "for i in soup7.find_all('a',class_='LatestNews-headline'):\n",
    "    Headline.append(i.text)\n",
    "    \n",
    "# Time    \n",
    "Time=[]\n",
    "for i in soup7.find_all('time',class_='LatestNews-timestamp'):\n",
    "    Time.append(i.text)\n",
    "    \n",
    "# News Link\n",
    "newsLink=[]\n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     newsLink.append(i.find(\"a\",class_=\"LatestNews-headline\").get(\"href\"))\n",
    "        \n",
    "# making dataframes\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Head Line':Headline,'Time':Time, 'News Link':newsLink})\n",
    "print('\\033[1m'+'Latest News Details from CNBC'+'\\033[0m')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5680e5",
   "metadata": {},
   "source": [
    "#### 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data frame\n",
    "    i) Paper Title\n",
    "    ii) Authors\n",
    "    iii) Published Date\n",
    "    iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "342be492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMost downloaded articles from AI in last 90 days\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get ('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "\n",
    "soup8=BeautifulSoup(page.content)\n",
    "\n",
    "# Paper Title\n",
    "Title=[]\n",
    "for i in soup8.find_all('a',class_='sc-5smygv-0 fIXTHm'):\n",
    "    Title.append(i.text)\n",
    "    \n",
    "# Authors\n",
    "Authors=[]\n",
    "for i in soup8.find_all('span',class_='sc-1w3fpd7-0 dnCnAO'):\n",
    "    Authors.append(i.text)\n",
    "    \n",
    "# Published Date    \n",
    "Published_Date=[]\n",
    "for i in soup8.find_all('span',class_='sc-1thf9ly-2 dvggWt'):\n",
    "    Published_Date.append(i.text)\n",
    "    \n",
    "# Paper URL\n",
    "Paper_URL=[]\n",
    "for i in soup8.find_all(\"li\",class_=\"sc-9zxyh7-1 sc-9zxyh7-2 kOEIEO hvoVxs\"):\n",
    "    Paper_URL.append(i.find(\"a\",class_=\"sc-5smygv-0 fIXTHm\").get(\"href\"))\n",
    "    \n",
    "    \n",
    "# making dataframes\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Paper Title':Title,'Authors':Authors,'Published Date':Published_Date, 'Paper URL':Paper_URL})\n",
    "print('\\033[1m'+'Most downloaded articles from AI in last 90 days'+'\\033[0m')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1377e",
   "metadata": {},
   "source": [
    "### 9) Write a python program to scrape mentioned details from dineout.co.in and make data frame\n",
    "    i) Restaurant name\n",
    "    ii) Cuisine\n",
    "    iii) Location\n",
    "    iv) Ratings\n",
    "    v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae6bb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRestaurants Near Me in Delhi\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tamasha</td>\n",
       "      <td>Continental, Asian, Italian, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Local</td>\n",
       "      <td>North Indian, Asian, Continental</td>\n",
       "      <td>Scindia House,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe High 5</td>\n",
       "      <td>North Indian, Continental, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ministry Of Beer</td>\n",
       "      <td>North Indian, Continental, American, Asian</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Openhouse Cafe</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My Bar Square</td>\n",
       "      <td>Finger Food, Chinese, Continental, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Warehouse Cafe</td>\n",
       "      <td>North Indian, Chinese, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unplugged Courtyard</td>\n",
       "      <td>North Indian, Italian, Chinese, Turkish, Cont...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Station Bar</td>\n",
       "      <td>Italian, Chinese, North Indian, Fast Food</td>\n",
       "      <td>F-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lord of the Drinks</td>\n",
       "      <td>Chinese, North Indian, Fast Food</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Junkyard Cafe</td>\n",
       "      <td>North Indian, Continental, Chinese, Fast Food</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Berco's</td>\n",
       "      <td>Chinese, Thai</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>QBA</td>\n",
       "      <td>North Indian, Continental, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The G.T. Road</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38 Barracks</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>M-Block,Connaught Place, Central Delhi</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Somewhere Restaurant &amp; Bar</td>\n",
       "      <td>North Indian, Continental, Asian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Out Of The Box Courtyard</td>\n",
       "      <td>North Indian, Mediterranean, Chinese, Italian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dasaprakash</td>\n",
       "      <td>North Indian, South Indian, Beverages, Chines...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chido</td>\n",
       "      <td>North Indian, Italian, Continental, Asian, Fi...</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lazeez Affaire</td>\n",
       "      <td>North Indian, Mughlai, Chinese</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ardor 2.1 Restaurant and Lounge</td>\n",
       "      <td>North Indian, Chinese, Italian, Continental</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant Name  \\\n",
       "0                           Tamasha   \n",
       "1                             Local   \n",
       "2                       Cafe High 5   \n",
       "3                  Ministry Of Beer   \n",
       "4                    Openhouse Cafe   \n",
       "5                     My Bar Square   \n",
       "6                    Warehouse Cafe   \n",
       "7               Unplugged Courtyard   \n",
       "8                       Station Bar   \n",
       "9                Lord of the Drinks   \n",
       "10                The Junkyard Cafe   \n",
       "11                          Berco's   \n",
       "12                              QBA   \n",
       "13                    The G.T. Road   \n",
       "14                      38 Barracks   \n",
       "15       Somewhere Restaurant & Bar   \n",
       "16         Out Of The Box Courtyard   \n",
       "17                      Dasaprakash   \n",
       "18                            Chido   \n",
       "19                   Lazeez Affaire   \n",
       "20  Ardor 2.1 Restaurant and Lounge   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0           Continental, Asian, Italian, North Indian   \n",
       "1                    North Indian, Asian, Continental   \n",
       "2                  North Indian, Continental, Chinese   \n",
       "3          North Indian, Continental, American, Asian   \n",
       "4                        North Indian, Asian, Italian   \n",
       "5          Finger Food, Chinese, Continental, Italian   \n",
       "6                      North Indian, Chinese, Italian   \n",
       "7    North Indian, Italian, Chinese, Turkish, Cont...   \n",
       "8           Italian, Chinese, North Indian, Fast Food   \n",
       "9                    Chinese, North Indian, Fast Food   \n",
       "10      North Indian, Continental, Chinese, Fast Food   \n",
       "11                                      Chinese, Thai   \n",
       "12                 North Indian, Continental, Italian   \n",
       "13                                       North Indian   \n",
       "14                 North Indian, Chinese, Continental   \n",
       "15                   North Indian, Continental, Asian   \n",
       "16      North Indian, Mediterranean, Chinese, Italian   \n",
       "17   North Indian, South Indian, Beverages, Chines...   \n",
       "18   North Indian, Italian, Continental, Asian, Fi...   \n",
       "19                     North Indian, Mughlai, Chinese   \n",
       "20        North Indian, Chinese, Italian, Continental   \n",
       "\n",
       "                                        Location Rating  \\\n",
       "0                 Connaught Place, Central Delhi    4.2   \n",
       "1   Scindia House,Connaught Place, Central Delhi      4   \n",
       "2                 Connaught Place, Central Delhi      4   \n",
       "3         M-Block,Connaught Place, Central Delhi      4   \n",
       "4                 Connaught Place, Central Delhi    4.1   \n",
       "5                 Connaught Place, Central Delhi    3.9   \n",
       "6                 Connaught Place, Central Delhi    4.1   \n",
       "7                 Connaught Place, Central Delhi      4   \n",
       "8         F-Block,Connaught Place, Central Delhi      4   \n",
       "9                 Connaught Place, Central Delhi    4.2   \n",
       "10                Connaught Place, Central Delhi    4.1   \n",
       "11                Connaught Place, Central Delhi    4.3   \n",
       "12                Connaught Place, Central Delhi    4.2   \n",
       "13        M-Block,Connaught Place, Central Delhi    4.3   \n",
       "14        M-Block,Connaught Place, Central Delhi    4.3   \n",
       "15                Connaught Place, Central Delhi    4.1   \n",
       "16                Connaught Place, Central Delhi    4.1   \n",
       "17                Connaught Place, Central Delhi    4.2   \n",
       "18                Connaught Place, Central Delhi    4.2   \n",
       "19                Connaught Place, Central Delhi    4.1   \n",
       "20                Connaught Place, Central Delhi    4.1   \n",
       "\n",
       "                                            Image URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get ('https://www.dineout.co.in/delhi-restaurants/dineout-pay')\n",
    "soup9=BeautifulSoup(page.content)\n",
    "\n",
    "# Restaurant Name\n",
    "Name=[] # empty list for store the\n",
    "for i in soup9.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "        Name.append(i.text)\n",
    "        \n",
    "# Cuisine        \n",
    "Cuisine=[]\n",
    "for i in soup9.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    Cuisine.append(i.text.split('|')[1])\n",
    "    \n",
    "# Location   \n",
    "Location=[] # empty list for store the\n",
    "for i in soup9.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    Location.append(i.text)\n",
    "    \n",
    "# Ratings    \n",
    "Ratings=[] # empty list for store the\n",
    "for i in soup9.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "# Image URL    \n",
    "Image=[] # empty list for store the\n",
    "for i in soup9.find_all('img',class_=\"no-img\"):\n",
    "    Image.append(i.get('data-src'))\n",
    "    \n",
    "    \n",
    "# making dataframes\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Restaurant Name':Name,'Cuisine':Cuisine, 'Location':Location,'Rating':Ratings,'Image URL':Image})\n",
    "print('\\033[1m'+'Restaurants Near Me in Delhi'+'\\033[0m')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e003756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
